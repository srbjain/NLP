{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fakenews.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRXWMlQuxQIU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c02c277b-4a5e-4396-ddd3-c7235b509c52"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "dataset_fake = pd.read_csv(\"sample_data/Fake.csv\")\n",
        "dataset_fake[\"label\"]=1\n",
        "dataset_true = pd.read_csv(\"sample_data/True.csv\")\n",
        "dataset_true[\"label\"]=0\n",
        "\n",
        "dataset = pd.concat((dataset_fake,dataset_true), axis=0)\n",
        "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "X = dataset.title\n",
        "y = dataset.label"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmILuzmfx4w6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "corpus = []\n",
        "for i in range(len(X)):\n",
        "    news = re.sub( \"[^a-zA-Z]\",\" \",X[i])\n",
        "    news = news.lower()\n",
        "    news = news.split()\n",
        "    sub_corpus = [ps.stem(word) for word in news if not word in stopwords.words(\"english\")]\n",
        "    sub_corpus = \" \".join(sub_corpus)\n",
        "    corpus.append(sub_corpus)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM8JrQZ1xxDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "\n",
        "input_len = 1000\n",
        "oh = [one_hot(word, input_len) for word in corpus]\n",
        "\n",
        "ohp = pad_sequences(oh, padding = \"post\")\n",
        "sent_len = len(ohp[0])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxfRN-FAxa39",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "6defaceb-62b1-4178-e38b-257293cc0ad7"
      },
      "source": [
        "output_len = 50\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_len, output_len, input_length=sent_len))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "print(model.summary())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 35, 50)            50000     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 35, 50)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               60400     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 110,501\n",
            "Trainable params: 110,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwSZ-vngxa8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_final = np.array(ohp)\n",
        "y_final = np.array(y)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size =0.2, random_state=20)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awPLfIHyxXX5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "f6a6bdd3-24b2-4236-8613-b0059c5d01da"
      },
      "source": [
        "model.fit(X_train,y_train,validation_data=(X_test,y_test), epochs=10, batch_size=64)\n",
        "y_pred = model.predict_classes(X_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "562/562 [==============================] - 4s 7ms/step - loss: 0.0714 - accuracy: 0.9733 - val_loss: 0.3001 - val_accuracy: 0.9166\n",
            "Epoch 2/10\n",
            "562/562 [==============================] - 4s 7ms/step - loss: 0.0668 - accuracy: 0.9748 - val_loss: 0.2919 - val_accuracy: 0.9164\n",
            "Epoch 3/10\n",
            "562/562 [==============================] - 4s 7ms/step - loss: 0.0658 - accuracy: 0.9755 - val_loss: 0.2943 - val_accuracy: 0.9192\n",
            "Epoch 4/10\n",
            "562/562 [==============================] - 4s 7ms/step - loss: 0.0644 - accuracy: 0.9764 - val_loss: 0.2927 - val_accuracy: 0.9161\n",
            "Epoch 5/10\n",
            "562/562 [==============================] - 4s 8ms/step - loss: 0.0626 - accuracy: 0.9768 - val_loss: 0.2947 - val_accuracy: 0.9188\n",
            "Epoch 6/10\n",
            "562/562 [==============================] - 4s 7ms/step - loss: 0.0630 - accuracy: 0.9765 - val_loss: 0.2845 - val_accuracy: 0.9188\n",
            "Epoch 7/10\n",
            "562/562 [==============================] - 4s 7ms/step - loss: 0.0582 - accuracy: 0.9779 - val_loss: 0.3236 - val_accuracy: 0.9195\n",
            "Epoch 8/10\n",
            "562/562 [==============================] - 4s 8ms/step - loss: 0.0546 - accuracy: 0.9799 - val_loss: 0.3099 - val_accuracy: 0.9188\n",
            "Epoch 9/10\n",
            "562/562 [==============================] - 4s 7ms/step - loss: 0.0541 - accuracy: 0.9802 - val_loss: 0.3151 - val_accuracy: 0.9198\n",
            "Epoch 10/10\n",
            "562/562 [==============================] - 4s 7ms/step - loss: 0.0506 - accuracy: 0.9824 - val_loss: 0.3158 - val_accuracy: 0.9205\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9204899777282851"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qHixIEkCT5z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9427f98-07c4-4d1f-e50d-a23e6c6d374e"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test,y_pred)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9204899777282851"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5nfLXb2Ci6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}